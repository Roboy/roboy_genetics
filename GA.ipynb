{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic algo for lighthouse sensor distribution on arbitrary mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from stl import mesh as meshstl\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "from data.plotmesh import plot_mesh\n",
    "import math\n",
    "import random\n",
    "from pyquaternion import Quaternion\n",
    "from scipy.linalg import qr\n",
    "import roslib\n",
    "import rospy\n",
    "import math\n",
    "import tf\n",
    "rospy.init_node('fixed_tf_broadcaster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many sensors would u like to distribute?\n",
    "sensorsToDistribute = 6\n",
    "stl_file = 'roboy_models/TestCube/stls/IcoSphere_360.stl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([-2.0, 0, 2.0], Quaternion(0.70710678118654757, -0.0, -0.0, -0.70710678118654746))\n",
      "([2, 0.0, 2.0], Quaternion(0.70710678118654757, 0.0, 0.0, 0.70710678118654746))\n"
     ]
    }
   ],
   "source": [
    "#Move Lighthouses to\n",
    "translationLH1 = [-2.,0,2.]\n",
    "quat1 = Quaternion(axis=[0,0,1],angle=-np.pi / 2)\n",
    "\n",
    "global LH1 \n",
    "LH1 = (translationLH1, quat1)\n",
    "\n",
    "translationLH2 = [2,0.,2.]\n",
    "quat2 = Quaternion(axis=[0,0,1], angle=np.pi / 2)\n",
    "\n",
    "global LH2\n",
    "LH2 = (translationLH2, quat2)\n",
    "\n",
    "print(LH1); print(LH2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.rvizMeshVis import meshVisualization\n",
    "\n",
    "scale = 0.01\n",
    "position = [0,0,0]\n",
    "global orientationMesh\n",
    "orientationMesh = Quaternion(axis=(1,0,0),angle = np.pi*0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    meshVisualization(orientationMesh, stl_file, color=(1.,1.,1.,1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484 triangles\n",
      "\n",
      "484 sensors in centers of triangles\n",
      "\n",
      "484 normals\n"
     ]
    }
   ],
   "source": [
    "from data.trisByDistance import *\n",
    "\n",
    "#Get mesh vertices and normals\n",
    "mesh1 = meshstl.Mesh.from_file(('../'+ stl_file))\n",
    "#mesh1 = meshstl.Mesh.from_file('../src/roboy_models/roboy_2_0_simplified/meshes/CAD/torso.stl')\n",
    "\n",
    "global triangles\n",
    "triangles = scale * np.matrix(mesh1.points)\n",
    "\n",
    "global trianglesBackup\n",
    "trianglesBackup = triangles\n",
    "\n",
    "global sortedTriangles\n",
    "\n",
    "lighthouses = [LH1, LH2]\n",
    "sortedTriangles = []\n",
    "\n",
    "normalsNotNorm = mesh1.normals\n",
    "global normals\n",
    "normals = []\n",
    "\n",
    "for normal in normalsNotNorm:\n",
    "    normals.append(1/np.linalg.norm(normal,2)*normal)\n",
    "    \n",
    "normals = np.matrix(normals)\n",
    "normals = scale * normals\n",
    "\n",
    "for l in lighthouses:\n",
    "    tris = trisByMinDistanceSortedMap(triangles, l[0])\n",
    "    sortedTriangles.append(tris)\n",
    "\n",
    "#vertices = np.reshape(triangles,(len(triangles)*3,3)) \n",
    "\n",
    "#Initialize sensors in centers of triangle\n",
    "sensors = (triangles[:,0:3]+triangles[:,3:6]+triangles[:,6:9])/3\n",
    "\n",
    "print('%d triangles' %len(triangles))\n",
    "print('')\n",
    "#print('%d vertices' %len(vertices))\n",
    "#print('')\n",
    "print('%d sensors in centers of triangles' %len(sensors))\n",
    "print('')\n",
    "print('%d normals' %len(normals))\n",
    "#print(normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.rvizNormalsVis import NormalsVisual\n",
    "\n",
    "#NormalsVisual(sensors,normals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from deap import algorithms, base, creator, tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sensors to dict\n",
    "global sensor_dict\n",
    "sensor_dict =  list(zip(range(len(sensors)), sensors.tolist()))\n",
    "\n",
    "global sensorDictBackup\n",
    "sensorDictBackup = sensor_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.rvizSensorVis import sensorVisualization\n",
    "\n",
    "#color = (r,g,b,a)\n",
    "sensorVisualization(sensor_dict, rate=500, sphereSize=0.03, color=(0,0,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1,)) # 1 -> maximum probblem\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.randomSensor import randomSensor\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "# Attribute generator \n",
    "toolbox.register(\"attr_bool\", randomSensor, sensor_dict)\n",
    "# Structure initializers\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, \n",
    "    toolbox.attr_bool, sensorsToDistribute)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toolbox.attr_bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[204, 123, 437, 412, 188, 184]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toolbox.individual()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (Fitness) Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.RayIntersectsTriangle import rayIntersectsTriangle, rayIntersectsTriangleVisual\n",
    "\n",
    "def FitnessFunction(sensors):\n",
    "    \n",
    "    br = tf.TransformBroadcaster()\n",
    "    br.sendTransform((LH1[0][0], LH1[0][1], LH1[0][2]),\n",
    "                     (quat1[0], quat1[1], quat1[2], quat1[3]),\n",
    "                     rospy.Time.now(),\n",
    "                     \"lighthouse1\",\n",
    "                     \"world\")\n",
    "    br.sendTransform((LH2[0][0], LH2[0][1], LH2[0][2]),\n",
    "                     (quat2[0], quat2[1], quat2[2], quat2[3]),\n",
    "                     rospy.Time.now(),\n",
    "                     \"lighthouse2\",\n",
    "                     \"world\")\n",
    "\n",
    "    \n",
    "    #1. COMPUTE VISIBLE SENSORS AT THE MOMENT\n",
    "    LH1_array = np.asarray(LH1[0])\n",
    "    LH2_array = np.asarray(LH2[0])\n",
    "    #testTriangle = np.squeeze(np.asarray(triangles[0]))\n",
    "\n",
    "    visibleLH1 = 0.0\n",
    "    visibleLH2 = 0.0\n",
    "    angleLH1 = []\n",
    "\n",
    "    for i, nmbr_sensor in enumerate(sensors):\n",
    "        sensor = sensor_dict[nmbr_sensor][1]\n",
    "\n",
    "        #get distance of current sensor and check if intersection\n",
    "        interDistLH1 = rayIntersectsTriangle(LH1_array, sensor, \n",
    "                                             np.squeeze(np.asarray(triangles[nmbr_sensor])), 'lighthouse1')\n",
    "        distLH1 = np.linalg.norm(np.asarray(sensor) - LH1_array)\n",
    "        interDistLH2 = rayIntersectsTriangle(LH2_array, sensor, \n",
    "                                             np.squeeze(np.asarray(triangles[nmbr_sensor])), 'lighthouse2')\n",
    "        distLH2 = np.linalg.norm(np.asarray(sensor) - LH2_array)\n",
    "        \n",
    "        # get angle between lighthouse vector and normal\n",
    "        normal = np.squeeze(np.asarray(normals[nmbr_sensor]))\n",
    "        #LH1\n",
    "        sensorToLH1 = sensor + (LH1_array - sensor)\n",
    "        angleLH1 = np.dot(sensorToLH1,normal)/(np.linalg.norm(sensorToLH1)*np.linalg.norm(normal))\n",
    "        angleLH1 = np.arccos(angleLH1)\n",
    "        #LH2\n",
    "        sensorToLH2 = sensor + (LH2_array - sensor)\n",
    "        angleLH2 = np.dot(sensorToLH2,normal)/(np.linalg.norm(sensorToLH2)*np.linalg.norm(normal))\n",
    "        angleLH2 = np.arccos(angleLH2)\n",
    "        \n",
    "        # Might be changed to something different\n",
    "        # Calculate visibility factor depending on angle between normal and lighthouse\n",
    "        visFactorLH1 = np.cos(angleLH1)\n",
    "        visFactorLH2 = np.cos(angleLH2)\n",
    "        \n",
    "        #print(\"Sensor %d has VisFactor %f mit LH1\"%(nmbr_sensor, visFactorLH1))\n",
    "        #print(\"Sensor %d has VisFactor %f mit LH2\"%(nmbr_sensor, visFactorLH2))\n",
    "        \n",
    "        \n",
    "        #print('interDist');print(interDistLH1);print(interDistLH2);print('endinterDist')\n",
    "\n",
    "        isVisible1 = True\n",
    "        isVisible2 = True\n",
    "        \n",
    "        # 1st lighthouse\n",
    "        if(visFactorLH1 > 0):\n",
    "            for (j, dist) in sortedTriangles[0]:\n",
    "                if(nmbr_sensor != j):\n",
    "                    #print(\"Testing sensor %i vs tris %i: distance of Sensor %f vs triangle %f\" % (i\n",
    "                    #, j, distLH1, dist))\n",
    "                    tris = triangles[j]\n",
    "                    newInterDistLH1 = rayIntersectsTriangle(LH1_array, sensor, \n",
    "                                                        np.squeeze(np.asarray(tris)), 'lighthouse1')#,j)\n",
    "                    if(newInterDistLH1 < interDistLH1 and newInterDistLH1 != False):\n",
    "                        isVisible1 = False\n",
    "                    if(not isVisible1 or dist > distLH1):\n",
    "                        # Break if not visible or already checked all tris\n",
    "                        # that are located closer to the lighthouse that the sensor\n",
    "                        break\n",
    "            if(isVisible1):\n",
    "                visibleLH1 += visFactorLH1\n",
    "                    \n",
    "        # 2nd lighthouse\n",
    "        if(visFactorLH2 > 0):\n",
    "            for (j, dist) in sortedTriangles[1]:\n",
    "                if(nmbr_sensor != j):\n",
    "                    tris = triangles[j]\n",
    "                    newInterDistLH2 = rayIntersectsTriangle(LH2_array, sensor, \n",
    "                                                        np.squeeze(np.asarray(tris)), 'lighthouse2')#,j)\n",
    "                    if(newInterDistLH2 < interDistLH2 and newInterDistLH2 != False):\n",
    "                        isVisible2 = False\n",
    "                    if(not isVisible2 or dist > distLH2):\n",
    "                        # Break if not visible or already checked all tris\n",
    "                        # that are located closer to the lighthouse that the sensor\n",
    "                        break\n",
    "            if(isVisible2):\n",
    "                visibleLH2 += visFactorLH2\n",
    "        #print(newInterDistLH1); print(newInterDistLH2)\n",
    "    \n",
    "    fractionVisibleLH1 = float(visibleLH1) / sensorsToDistribute\n",
    "    fractionVisibleLH2 = float(visibleLH2) / sensorsToDistribute\n",
    "        \n",
    "    #2. COMPUTE EUCLIDEAN DISTANCE OF SENSORS\n",
    "    individual = sensors\n",
    "    dist = 0\n",
    "    for i,ind in enumerate(individual):\n",
    "        ind = np.asarray(sensor_dict[ind][1])\n",
    "        for j in range(i,len(individual)):\n",
    "            if(i != j):\n",
    "                indivi = np.asarray(sensor_dict[individual[j]][1])\n",
    "                dist += np.linalg.norm(ind-indivi)\n",
    "    dist = dist/(sensorsToDistribute)\n",
    "\n",
    "    #print(visibleLH1);print(visibleLH2);print('')\n",
    "    \n",
    "    return (fractionVisibleLH1 + fractionVisibleLH2 + dist),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.register(\"evaluate\", FitnessFunction)\n",
    "\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "# Independent probability  : for each attribute to be mutated.# low~up rondom int\n",
    "toolbox.register(\"mutate\", tools.mutUniformInt, low=0, up=len(sensors.tolist())-1, indpb=0.2) \n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating population\n",
    "\n",
    "population = toolbox.population(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hof = tools.HallOfFame(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"std\", np.std)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from data.algorithmsMod import varAnd\n",
    "from deap import tools\n",
    "from data.trafomatrix import getRandomRotationmatrix\n",
    "from data.bestSensorVis import bestSensorVis\n",
    "\n",
    "#MODDED VERSION of eaSimple from DEAP\n",
    "def eaSimpleMod(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
    "             halloffame=None, verbose=__debug__):\n",
    "    \"\"\"This algorithm reproduce the simplest evolutionary algorithm as\n",
    "    presented in chapter 7 of [Back2000]_.\n",
    "    \n",
    "    Modded version of DEAP Evolutionary Algorithm Framework\n",
    "    https://github.com/DEAP/deap\n",
    "    \"\"\"\n",
    "    global sensor_dict\n",
    "    global triangles\n",
    "    global orientationMesh\n",
    "    \n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is not None:\n",
    "        halloffame.update(population)\n",
    "\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print logbook.stream\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population))\n",
    "\n",
    "        # Vary the pool of individuals\n",
    "        offspring = varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        if halloffame is not None:\n",
    "            halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print logbook.stream\n",
    "        \n",
    "        sensorMovement = tools.selBest(population, k=1)[0]\n",
    "        bestSensorVis(sensor_dict, sensorMovement, rate=500, color=(0,1,0,0.8), sphereSize=0.2)\n",
    "        \n",
    "        if(gen%10==0):\n",
    "            global sensorDictBackup\n",
    "            global trianglesBackup\n",
    "            sensor_dict = sensorDictBackup\n",
    "            R = getRandomRotationmatrix()\n",
    "            sensorDictNew = []\n",
    "            \n",
    "            for sensor in sensor_dict:\n",
    "                sensorDictNew.append(np.squeeze(np.asarray(R.dot(np.array(sensor[1])))).tolist())\n",
    "                \n",
    "            sensor_dict = list(zip(range(len(sensorDictNew)), sensorDictNew))\n",
    "        \n",
    "            tri1 = R.dot(np.transpose(trianglesBackup[:,0:3]))\n",
    "            tri2 = R.dot(np.transpose(trianglesBackup[:,3:6]))\n",
    "            tri3 = R.dot(np.transpose(trianglesBackup[:,6:9]))\n",
    "\n",
    "            triangles = np.concatenate((tri1.T,tri2.T,tri3.T),axis=1)\n",
    "            \n",
    "            # resort the triangles by distance from lighthouses for speedup\n",
    "            global sortedTriangles\n",
    "\n",
    "            lighthouses = [LH1, LH2]\n",
    "            sortedTriangles = []\n",
    "\n",
    "            for l in lighthouses:\n",
    "                tris = trisByMinDistanceSortedMap(triangles, l[0])\n",
    "                sortedTriangles.append(tris)\n",
    "                \n",
    "                \n",
    "\n",
    "            orientationMesh = Quaternion(matrix=R)\n",
    "            \n",
    "            meshVisualization(orientationMesh, stl_file, color=(1.,1.,1.,1.))\n",
    "            sensorVisualization(sensor_dict, rate=500, sphereSize=0.03, color=(0,0,1,1))\n",
    "            \n",
    "            \n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg    \tstd    \tmin    \tmax    \n",
      "0  \t50    \t3.83805\t0.29771\t2.95157\t4.23495\n",
      "1  \t40    \t3.92916\t0.233593\t3.23858\t4.24793\n",
      "2  \t33    \t4.06427\t0.181472\t3.44415\t4.27891\n",
      "3  \t28    \t4.0671 \t0.259315\t2.72735\t4.27891\n",
      "4  \t33    \t4.13253\t0.179135\t3.49216\t4.27891\n",
      "5  \t33    \t4.15815\t0.108781\t3.89279\t4.27891\n",
      "6  \t22    \t4.22385\t0.078825\t3.9343 \t4.35568\n",
      "7  \t31    \t4.20357\t0.160162\t3.47887\t4.35568\n",
      "8  \t24    \t4.22718\t0.158304\t3.40794\t4.35568\n",
      "9  \t29    \t4.2789 \t0.0849768\t3.90192\t4.35568\n",
      "10 \t38    \t4.26646\t0.118283 \t3.77909\t4.35568\n",
      "11 \t32    \t4.30504\t0.0945863\t3.85669\t4.35568\n",
      "12 \t30    \t4.32614\t0.0754385\t3.94931\t4.35568\n",
      "13 \t26    \t4.3154 \t0.114057 \t3.87355\t4.35568\n",
      "14 \t38    \t4.32096\t0.089049 \t3.90414\t4.35568\n",
      "15 \t19    \t4.3269 \t0.0780439\t3.91677\t4.35568\n",
      "16 \t30    \t4.3061 \t0.121755 \t3.70617\t4.35568\n",
      "17 \t35    \t4.28974\t0.188638 \t3.39934\t4.35568\n",
      "18 \t27    \t4.3184 \t0.110596 \t3.92188\t4.35568\n",
      "19 \t32    \t4.2923 \t0.163351 \t3.62289\t4.35568\n",
      "20 \t33    \t4.33338\t0.0818526\t3.89122\t4.35568\n",
      "21 \t34    \t4.1356 \t0.167956 \t3.69003\t4.35568\n",
      "22 \t29    \t4.09999\t0.147265 \t3.6556 \t4.35568\n",
      "23 \t34    \t4.06159\t0.152773 \t3.4166 \t4.35568\n",
      "24 \t22    \t4.04915\t0.183791 \t3.48886\t4.35568\n",
      "25 \t38    \t4.0301 \t0.178135 \t3.36418\t4.35568\n",
      "26 \t29    \t4.07085\t0.141991 \t3.60991\t4.35568\n",
      "27 \t30    \t4.08297\t0.137038 \t3.72443\t4.35568\n",
      "28 \t17    \t4.11831\t0.152823 \t3.50964\t4.35568\n",
      "29 \t25    \t4.16066\t0.166663 \t3.75499\t4.35568\n",
      "30 \t27    \t4.11797\t0.199128 \t3.36231\t4.35568\n",
      "31 \t28    \t3.96786\t0.284897 \t3.40691\t4.35568\n",
      "32 \t25    \t3.96777\t0.289046 \t3.47241\t4.35568\n",
      "33 \t29    \t3.91508\t0.315001 \t2.80016\t4.35568\n",
      "34 \t30    \t3.91465\t0.269551 \t3.51228\t4.35568\n",
      "35 \t36    \t3.80499\t0.241789 \t3.33559\t4.35568\n",
      "36 \t32    \t3.84677\t0.248976 \t3.4354 \t4.35568\n",
      "37 \t30    \t3.81657\t0.185941 \t3.43634\t4.35568\n",
      "38 \t33    \t3.7655 \t0.169735 \t3.01469\t4.35568\n",
      "39 \t36    \t3.7727 \t0.158863 \t3.33736\t4.35568\n",
      "40 \t24    \t3.85988\t0.190587 \t3.58616\t4.35568\n",
      "41 \t33    \t3.93877\t0.180279 \t3.46652\t4.35568\n",
      "42 \t30    \t4.01634\t0.15099  \t3.5085 \t4.35568\n",
      "43 \t32    \t4.00573\t0.207269 \t3.04078\t4.35568\n",
      "44 \t29    \t4.06108\t0.140072 \t3.69506\t4.35568\n",
      "45 \t30    \t4.09113\t0.173824 \t3.49709\t4.35568\n",
      "46 \t26    \t4.12027\t0.166657 \t3.64446\t4.35568\n",
      "47 \t38    \t4.04187\t0.151078 \t3.64909\t4.35568\n",
      "48 \t33    \t4.02565\t0.163864 \t3.31425\t4.35568\n",
      "49 \t29    \t4.06115\t0.0882596\t3.74951\t4.35568\n",
      "50 \t37    \t4.07487\t0.0549559\t3.88988\t4.35568\n",
      "51 \t36    \t4.0104 \t0.11925  \t3.62079\t4.35568\n",
      "52 \t34    \t4.03712\t0.104415 \t3.68279\t4.35568\n",
      "53 \t21    \t4.02206\t0.163631 \t3.33395\t4.35568\n",
      "54 \t34    \t4.01198\t0.182472 \t3.25845\t4.35568\n",
      "55 \t27    \t4.01602\t0.145274 \t3.50366\t4.35568\n",
      "56 \t41    \t4.02798\t0.122715 \t3.61051\t4.35568\n",
      "57 \t34    \t4.01924\t0.127838 \t3.51066\t4.35568\n",
      "58 \t31    \t4.01438\t0.12139  \t3.42052\t4.35568\n",
      "59 \t26    \t4.01292\t0.120278 \t3.54349\t4.35568\n",
      "60 \t21    \t4.01328\t0.130505 \t3.36228\t4.35568\n",
      "61 \t28    \t3.96036\t0.133418 \t3.37224\t4.35568\n",
      "62 \t31    \t3.91372\t0.166455 \t3.04002\t4.04999\n",
      "63 \t36    \t3.92293\t0.0586875\t3.64248\t4.04999\n",
      "64 \t29    \t3.90683\t0.116127 \t3.41969\t4.04999\n",
      "65 \t32    \t3.90948\t0.120112 \t3.43385\t4.04999\n",
      "66 \t30    \t3.88966\t0.180273 \t3.23179\t4.04999\n",
      "67 \t33    \t3.91879\t0.128389 \t3.2324 \t4.04999\n",
      "68 \t32    \t3.91387\t0.108248 \t3.55289\t4.04999\n",
      "69 \t27    \t3.91813\t0.129303 \t3.33227\t4.04999\n",
      "70 \t28    \t3.93457\t0.0992982\t3.46103\t4.04999\n",
      "71 \t34    \t3.97583\t0.104578 \t3.48612\t4.08691\n",
      "72 \t26    \t4.01601\t0.0641376\t3.7421 \t4.08691\n",
      "73 \t35    \t4.00683\t0.101783 \t3.64786\t4.08691\n",
      "74 \t38    \t4.01937\t0.130956 \t3.27825\t4.08691\n",
      "75 \t38    \t4.0049 \t0.156996 \t3.42526\t4.09304\n",
      "76 \t27    \t4.0567 \t0.0965974\t3.49453\t4.09304\n",
      "77 \t33    \t4.04824\t0.0724817\t3.82307\t4.08691\n",
      "78 \t31    \t4.01787\t0.176528 \t3.16164\t4.08691\n",
      "79 \t23    \t4.04185\t0.174652 \t3.06862\t4.09402\n",
      "80 \t40    \t4.0502 \t0.102483 \t3.52584\t4.09402\n",
      "81 \t35    \t3.89692\t0.149842 \t3.43016\t4.09402\n",
      "82 \t28    \t3.90607\t0.160283 \t3.29274\t4.09402\n",
      "83 \t29    \t3.90572\t0.178694 \t3.06267\t4.09402\n",
      "84 \t31    \t3.89421\t0.155899 \t3.42723\t4.09402\n",
      "85 \t27    \t3.92582\t0.134176 \t3.59336\t4.09402\n",
      "86 \t30    \t3.9227 \t0.138207 \t3.45899\t4.09402\n",
      "87 \t27    \t3.95173\t0.108011 \t3.7809 \t4.09402\n",
      "88 \t40    \t3.89334\t0.117963 \t3.60362\t4.09402\n",
      "89 \t26    \t3.92668\t0.1374   \t3.55135\t4.09402\n",
      "90 \t37    \t3.9056 \t0.139988 \t3.31548\t4.09402\n",
      "91 \t32    \t4.00512\t0.118683 \t3.54185\t4.15256\n",
      "92 \t34    \t4.03735\t0.16101  \t3.26333\t4.1571 \n",
      "93 \t20    \t4.07693\t0.153346 \t3.24745\t4.16057\n",
      "94 \t35    \t4.10375\t0.149405 \t3.31262\t4.1571 \n",
      "95 \t33    \t4.11944\t0.108244 \t3.55343\t4.1571 \n",
      "96 \t22    \t4.12175\t0.112269 \t3.449  \t4.1571 \n",
      "97 \t29    \t4.11379\t0.146883 \t3.14869\t4.1571 \n",
      "98 \t27    \t4.13868\t0.0584988\t3.88646\t4.18003\n",
      "99 \t37    \t4.11793\t0.0981313\t3.70167\t4.18003\n",
      "100\t29    \t4.13515\t0.0708926\t3.82585\t4.1571 \n"
     ]
    }
   ],
   "source": [
    "population, log = eaSimpleMod(population, \n",
    "                                toolbox, \n",
    "                                cxpb=0.5, \n",
    "                                mutpb=0.2, \n",
    "                                ngen=100, \n",
    "                                stats=stats, \n",
    "                                halloffame=hof, \n",
    "                                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[125, 214, 46, 196, 15, 322], [125, 214, 46, 196, 15, 322], [125, 214, 46, 196, 15, 322]]\n"
     ]
    }
   ],
   "source": [
    "bestSensors = tools.selBest(population, k=3)\n",
    "print(bestSensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from data.bestSensorVis import bestSensorVis\n",
    "#Sensor visualization in RVIZ\n",
    "\n",
    "bestSensorVis(sensor_dict, bestSensors[0], rate=500, color=(1,0,0,0.8), sphereSize=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
