{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic algo for lighthouse sensor distribution on arbitrary mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from stl import mesh as meshstl\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "from data.plotmesh import plot_mesh\n",
    "import math\n",
    "import random\n",
    "from pyquaternion import Quaternion\n",
    "from scipy.linalg import qr\n",
    "import roslib\n",
    "import rospy\n",
    "import math\n",
    "import tf\n",
    "rospy.init_node('fixed_tf_broadcaster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# how many sensors would you like to distribute?\n",
    "sensorsToDistribute = 11\n",
    "\n",
    "# which mesh would you like to use?\n",
    "stl_file = 'roboy_models/TestCube/stls/monkey.stl'\n",
    "#stl_file = 'roboy_models/TestCube/stls/IcoSphere_360.stl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Move Lighthouses to\n",
    "translationLH1 = [-2.,0,2.]\n",
    "quat1 = Quaternion(axis=[0,0,1],angle=0*np.pi)\n",
    "\n",
    "global LH1 \n",
    "LH1 = (translationLH1, quat1)\n",
    "\n",
    "translationLH2 = [2,0.,2.]\n",
    "quat2 = Quaternion(axis=[1,0,0], angle= -np.pi)\n",
    "\n",
    "global LH2\n",
    "LH2 = (translationLH2, quat2)\n",
    "\n",
    "print(LH1); print(LH2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data.rvizMeshVis import meshVisualization\n",
    "\n",
    "scale = 0.01\n",
    "position = [0,0,0]\n",
    "global orientationMesh\n",
    "orientationMesh = Quaternion(axis=(1,0,0),angle = np.pi*0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    meshVisualization(orientationMesh, stl_file, color=(1.,1.,1.,0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data.trisByDistance import *\n",
    "\n",
    "#Get mesh vertices and normals\n",
    "mesh1 = meshstl.Mesh.from_file(('../'+ stl_file))\n",
    "#mesh1 = meshstl.Mesh.from_file('../src/roboy_models/roboy_2_0_simplified/meshes/CAD/torso.stl')\n",
    "\n",
    "global triangles\n",
    "triangles = scale * np.matrix(mesh1.points)\n",
    "\n",
    "global trianglesBackup\n",
    "trianglesBackup = triangles\n",
    "\n",
    "global sortedTriangles\n",
    "\n",
    "lighthouses = [LH1, LH2]\n",
    "sortedTriangles = []\n",
    "\n",
    "normalsNotNorm = mesh1.normals\n",
    "global normals\n",
    "normals = []\n",
    "\n",
    "for normal in normalsNotNorm:\n",
    "    normals.append(1/np.linalg.norm(normal,2)*normal)\n",
    "    \n",
    "normals = np.matrix(normals)\n",
    "normals = scale * normals\n",
    "\n",
    "for l in lighthouses:\n",
    "    tris = trisByMinDistanceSortedMap(triangles, l[0])\n",
    "    sortedTriangles.append(tris)\n",
    "\n",
    "#vertices = np.reshape(triangles,(len(triangles)*3,3)) \n",
    "\n",
    "#Initialize sensors in centers of triangle\n",
    "sensors = (triangles[:,0:3]+triangles[:,3:6]+triangles[:,6:9])/3\n",
    "\n",
    "print('%d triangles' %len(triangles))\n",
    "print('')\n",
    "#print('%d vertices' %len(vertices))\n",
    "#print('')\n",
    "print('%d sensors in centers of triangles' %len(sensors))\n",
    "print('')\n",
    "print('%d normals' %len(normals))\n",
    "#print(normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data.rvizNormalsVis import NormalsVisual\n",
    "\n",
    "#NormalsVisual(sensors,normals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from deap import algorithms, base, creator, tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sensors to dict\n",
    "global sensor_dict\n",
    "sensor_dict =  list(zip(range(len(sensors)), sensors.tolist()))\n",
    "\n",
    "global sensorDictBackup\n",
    "sensorDictBackup = sensor_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data.rvizSensorVis import sensorVisualization\n",
    "\n",
    "#color = (r,g,b,a)\n",
    "sensorVisualization(sensor_dict, rate=500, sphereSize=0.03, color=(0,0,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1,)) # 1 -> maximum probblem\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data.randomSensor import randomSensor\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "# Attribute generator \n",
    "toolbox.register(\"attr_bool\", randomSensor, sensor_dict)\n",
    "# Structure initializers\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, \n",
    "    toolbox.attr_bool, sensorsToDistribute)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.attr_bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.individual()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (Fitness) Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data.RayIntersectsTriangle import rayIntersectsTriangle, rayIntersectsTriangleVisual\n",
    "\n",
    "def FitnessFunction(sensors):\n",
    "    \n",
    "    br = tf.TransformBroadcaster()\n",
    "    br.sendTransform((LH1[0][0], LH1[0][1], LH1[0][2]),\n",
    "                     (quat1[0], quat1[1], quat1[2], quat1[3]),\n",
    "                     rospy.Time.now(),\n",
    "                     \"lighthouse1\",\n",
    "                     \"world\")\n",
    "    br.sendTransform((LH2[0][0], LH2[0][1], LH2[0][2]),\n",
    "                     (quat2[0], quat2[1], quat2[2], quat2[3]),\n",
    "                     rospy.Time.now(),\n",
    "                     \"lighthouse2\",\n",
    "                     \"world\")\n",
    "\n",
    "    \n",
    "    #1. COMPUTE VISIBLE SENSORS AT THE MOMENT\n",
    "    LH1_array = np.asarray(LH1[0])\n",
    "    LH2_array = np.asarray(LH2[0])\n",
    "    #testTriangle = np.squeeze(np.asarray(triangles[0]))\n",
    "\n",
    "    visibleLH1 = 0.0\n",
    "    visibleLH2 = 0.0\n",
    "    angleLH1 = []\n",
    "\n",
    "    for i, nmbr_sensor in enumerate(sensors):\n",
    "        sensor = sensor_dict[nmbr_sensor][1]\n",
    "\n",
    "        #get distance of current sensor and check if intersection\n",
    "        interDistLH1 = rayIntersectsTriangle(LH1_array, sensor, \n",
    "                                             np.squeeze(np.asarray(triangles[nmbr_sensor])), 'lighthouse1')\n",
    "        distLH1 = np.linalg.norm(np.asarray(sensor) - LH1_array)\n",
    "        interDistLH2 = rayIntersectsTriangle(LH2_array, sensor, \n",
    "                                             np.squeeze(np.asarray(triangles[nmbr_sensor])), 'lighthouse2')\n",
    "        distLH2 = np.linalg.norm(np.asarray(sensor) - LH2_array)\n",
    "        \n",
    "        # get angle between lighthouse vector and normal\n",
    "        normal = np.squeeze(np.asarray(normals[nmbr_sensor]))\n",
    "        #LH1\n",
    "        sensorToLH1 = sensor + (LH1_array - sensor)\n",
    "        angleLH1 = np.dot(sensorToLH1,normal)/(np.linalg.norm(sensorToLH1)*np.linalg.norm(normal))\n",
    "        #angleLH1 = np.arccos(angleLH1)\n",
    "        #LH2\n",
    "        sensorToLH2 = sensor + (LH2_array - sensor)\n",
    "        angleLH2 = np.dot(sensorToLH2,normal)/(np.linalg.norm(sensorToLH2)*np.linalg.norm(normal))\n",
    "        #angleLH2 = np.arccos(angleLH2)\n",
    "        \n",
    "        # Might be changed to something different\n",
    "        # Calculate visibility factor depending on angle between normal and lighthouse\n",
    "        visFactorLH1 = angleLH1#np.cos(angleLH1)\n",
    "        visFactorLH2 = angleLH2#np.cos(angleLH2)\n",
    "        \n",
    "        #print(\"Sensor %d has VisFactor %f mit LH1\"%(nmbr_sensor, visFactorLH1))\n",
    "        #print(\"Sensor %d has VisFactor %f mit LH2\"%(nmbr_sensor, visFactorLH2))\n",
    "        \n",
    "        \n",
    "        #print('interDist');print(interDistLH1);print(interDistLH2);print('endinterDist')\n",
    "\n",
    "        isVisible1 = True\n",
    "        isVisible2 = True\n",
    "        \n",
    "        # 1st lighthouse\n",
    "        if(visFactorLH1 > 0):\n",
    "            for (j, dist) in sortedTriangles[0]:\n",
    "                if(nmbr_sensor != j):\n",
    "                    #print(\"Testing sensor %i vs tris %i: distance of Sensor %f vs triangle %f\" % (i\n",
    "                    #, j, distLH1, dist))\n",
    "                    tris = triangles[j]\n",
    "                    newInterDistLH1 = rayIntersectsTriangle(LH1_array, sensor, \n",
    "                                                        np.squeeze(np.asarray(tris)), 'lighthouse1')#,j)\n",
    "                    if(newInterDistLH1 < interDistLH1 and newInterDistLH1 != False):\n",
    "                        isVisible1 = False\n",
    "                    if(not isVisible1 or dist > distLH1):\n",
    "                        # Break if not visible or already checked all tris\n",
    "                        # that are located closer to the lighthouse that the sensor\n",
    "                        break\n",
    "            if(isVisible1):\n",
    "                visibleLH1 += visFactorLH1\n",
    "                    \n",
    "        # 2nd lighthouse\n",
    "        if(visFactorLH2 > 0):\n",
    "            for (j, dist) in sortedTriangles[1]:\n",
    "                if(nmbr_sensor != j):\n",
    "                    tris = triangles[j]\n",
    "                    newInterDistLH2 = rayIntersectsTriangle(LH2_array, sensor, \n",
    "                                                        np.squeeze(np.asarray(tris)), 'lighthouse2')#,j)\n",
    "                    if(newInterDistLH2 < interDistLH2 and newInterDistLH2 != False):\n",
    "                        isVisible2 = False\n",
    "                    if(not isVisible2 or dist > distLH2):\n",
    "                        # Break if not visible or already checked all tris\n",
    "                        # that are located closer to the lighthouse that the sensor\n",
    "                        break\n",
    "            if(isVisible2):\n",
    "                visibleLH2 += visFactorLH2\n",
    "        #print(newInterDistLH1); print(newInterDistLH2)\n",
    "    \n",
    "    fractionVisibleLH1 = float(visibleLH1) / sensorsToDistribute\n",
    "    fractionVisibleLH2 = float(visibleLH2) / sensorsToDistribute\n",
    "        \n",
    "    #2. COMPUTE EUCLIDEAN DISTANCE OF SENSORS\n",
    "    individual = sensors\n",
    "    dist = 0.0\n",
    "    distTemp = 0.0\n",
    "    distMax = 0.0\n",
    "    for i,ind in enumerate(individual):\n",
    "        ind = np.asarray(sensor_dict[ind][1])\n",
    "        for j in range(i,len(individual)):\n",
    "            if(i != j):\n",
    "                indivi = np.asarray(sensor_dict[individual[j]][1])\n",
    "                distTemp = np.linalg.norm(ind-indivi)\n",
    "                dist += distTemp\n",
    "                if(distTemp > distMax):\n",
    "                    distMax = distTemp\n",
    "    #print(dist);print(distMax)\n",
    "    distNorm = dist/(distMax * sensorsToDistribute)\n",
    "\n",
    "    #print(visibleLH1);print(visibleLH2);print('')\n",
    "    \n",
    "    return (fractionVisibleLH1 + fractionVisibleLH2 + distNorm),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toolbox.register(\"evaluate\", FitnessFunction)\n",
    "\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "# Independent probability  : for each attribute to be mutated.# low~up rondom int\n",
    "toolbox.register(\"mutate\", tools.mutUniformInt, low=0, up=len(sensors.tolist())-1, indpb=0.2) \n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating population\n",
    "\n",
    "population = toolbox.population(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hof = tools.HallOfFame(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"std\", np.std)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from data.algorithmsMod import varAnd\n",
    "from deap import tools\n",
    "from data.trafomatrix import getRandomRotationmatrix\n",
    "from data.bestSensorVis import bestSensorVis\n",
    "\n",
    "#MODDED VERSION of eaSimple from DEAP\n",
    "def eaSimpleMod(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
    "             halloffame=None, verbose=__debug__):\n",
    "    \"\"\"This algorithm reproduce the simplest evolutionary algorithm as\n",
    "    presented in chapter 7 of [Back2000]_.\n",
    "    \n",
    "    Modded version of DEAP Evolutionary Algorithm Framework\n",
    "    https://github.com/DEAP/deap\n",
    "    \"\"\"\n",
    "    global sensor_dict\n",
    "    global triangles\n",
    "    global orientationMesh\n",
    "    \n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is not None:\n",
    "        halloffame.update(population)\n",
    "\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print logbook.stream\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population))\n",
    "\n",
    "        # Vary the pool of individuals\n",
    "        offspring = varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        if halloffame is not None:\n",
    "            halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print logbook.stream\n",
    "        \n",
    "        #sensorMovement = tools.selBest(population, k=1)[0]\n",
    "        #bestSensorVis(sensor_dict, sensorMovement, rate=1000, color=(0,1,0,0.8), sphereSize=0.2)\n",
    "        \n",
    "        if(gen%1==0):\n",
    "            global sensorDictBackup\n",
    "            global trianglesBackup\n",
    "            sensor_dict = sensorDictBackup\n",
    "            R = getRandomRotationmatrix()\n",
    "            sensorDictNew = []\n",
    "            \n",
    "            for sensor in sensor_dict:\n",
    "                sensorDictNew.append(np.squeeze(np.asarray(R.dot(np.array(sensor[1])))).tolist())\n",
    "                \n",
    "            sensor_dict = list(zip(range(len(sensorDictNew)), sensorDictNew))\n",
    "        \n",
    "            tri1 = R.dot(np.transpose(trianglesBackup[:,0:3]))\n",
    "            tri2 = R.dot(np.transpose(trianglesBackup[:,3:6]))\n",
    "            tri3 = R.dot(np.transpose(trianglesBackup[:,6:9]))\n",
    "\n",
    "            triangles = np.concatenate((tri1.T,tri2.T,tri3.T),axis=1)\n",
    "            \n",
    "            # resort the triangles by distance from lighthouses for speedup\n",
    "            global sortedTriangles\n",
    "\n",
    "            lighthouses = [LH1, LH2]\n",
    "            sortedTriangles = []\n",
    "\n",
    "            for l in lighthouses:\n",
    "                tris = trisByMinDistanceSortedMap(triangles, l[0])\n",
    "                sortedTriangles.append(tris)\n",
    "                \n",
    "                \n",
    "\n",
    "            orientationMesh = Quaternion(matrix=R)\n",
    "            \n",
    "            meshVisualization(orientationMesh, stl_file, color=(1.,1.,1.,0.9))\n",
    "            #sensorVisualization(sensor_dict, rate=500, sphereSize=0.03, color=(0,0,1,1))\n",
    "            sensorMovement = tools.selBest(population, k=1)[0]\n",
    "            bestSensorVis(sensor_dict, sensorMovement, rate=1000, color=(0,1,0,0.8), sphereSize=0.2)\n",
    "            \n",
    "            \n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "population, log = eaSimpleMod(population, \n",
    "                                toolbox, \n",
    "                                cxpb=0.5, \n",
    "                                mutpb=0.5, \n",
    "                                ngen=150, \n",
    "                                stats=stats, \n",
    "                                halloffame=hof, \n",
    "                                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bestSensors = tools.selBest(population, k=1)\n",
    "print(bestSensors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from data.bestSensorVis import bestSensorVis\n",
    "\n",
    "#Sensor visualization in RVIZ\n",
    "orientationMesh = (0,0,0,0)\n",
    "meshVisualization(orientationMesh, stl_file, color=(1.,1.,1.,0.9))\n",
    "sensorVisualization(sensorDictBackup, rate=500, sphereSize=0.03, color=(0,0,1,1))\n",
    "bestSensorVis(sensorDictBackup, bestSensors[0], rate=500, color=(1,0,0,0.8), sphereSize=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
